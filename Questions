
1. The goal of this evaluation is to determine how the performance of this networked cache scales with the networked cache's parameters (discussed in part 4). We are comparing cache performance with different workloads on the same machine at approximately the same time to minimize the impact of extraneous variables beyond the system's boundaries such as background processes on our machine and general internet speed. We only want to measure the relative difference of performance for different parameter values.

 
2. System services and possible outcomes include:
	- create_cache: new cache gets created, or else error occurs (i.e. new cache not created or new cache created with wrong size/parameters)
	- delete_cache: specified cache deleted, or else error (i.e. cache not deleted, wrong cache deleted)
	- set: new key-value pair created if key not in cache, or existing key-value pair updated if key in cache, or nothing if no room for new value, or error (i.e. key gets wrong value, wrong key set to value)
	- get: nothing if key absent, key's value printed if key present, or error (i.e. wrong/no value returned, correct value returned but key-value pair modified in process)


3. Performance metrics which we want to measure include system performance (latency, throughput), accuracy (error rate) and availability (accessibility of cached information) relative to the cache's workload/parameters (discussed in part 4).

4. System parameters include internet speed, requirements of background processes, and quality of hardware on which program is running. Workload parameters include cache size (maxmem), cache capacity (memused), fill ratio of cache (memused:maxmem), frequency of requests to cache, and size of value associated with request (i.e. getting large vs small value).

5. Factors include cache size, cache fill ratio, and value size. Levels of cache size are 64, 4096, and 2**24. Levels of cache fill ratio are 0, 1/2, and 1. Levels of value size are 1 and 30. The networked cache we are studying does not appear to work - although it initially seemed to, tests were not over a network and when we tried to manipulate a networked cache instead of a non-networked one we receive a compilation error. Consequently, we chose not to measure the sustained throughput explicitly in our tests, although we know from the networked cache's lack of functionality exactly what the sustained throughput is - 0.

6. Due to the complexity of the target system, modeling and simulation are unlikely to yield reliable results. Consequently, we tested the cache by benchmarking the real system.

7. We measured each of the cache's services - create_cache, delete_cache, get, set and del - separately, with workloads for each service consisting of 1,000,000 requests of that type, varying across our chosen factors.

8. We implemented our experiment using many factors, each with a small but representative set of levels (i.e. for cache fill ratio we use only 3 levels spanning the entire space of level possibilities for that factor). Because we got similar results for each level, we found it unnecessary to fine-tune with many levels for more specific results, as our initial results did not leave a large amount of unexplained data. 

9. Our results indicate (for a non-networked cache) no effect of cache size, value size, or cache fill ratio on performance of create_cache, delete_cache, get, set or del. This is likely because the vast majority of time spent on any service is spent finding the location associated with a request, rather than actually writing/reading/deleting to/from that location. Cache size does not affect create/delete_cache because these operations simply declare a cache rather than actually iterating through the memory allocated for it. Cache_size and val_size don't affect set because the relevant location is the first slot at the index which the relevant key hashes to. It is slightly surprising that cache fill ratio doesn't affect get or del, since higher fill ratios would correlate with more items being iterated through to find desire location (due to bucket hashing), however resizing the hash table when the load factor exceeds a certain threshold could mitigate this additional overhead.
